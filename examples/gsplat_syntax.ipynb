{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_trainer import Config, Runner\n",
    "import json\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_and_make_config(config_file: str) -> Config:\n",
    "    import json\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return Config(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonstr1 = json.dumps(runner.cfg.__dict__, indent=2)\n",
    "\n",
    "with open('cfg_test.json', 'w') as f:\n",
    "    f.write(jsonstr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parser] 50 images, taken by 10 cameras.\n",
      "Scene scale: 1.4702541970170933\n",
      "Model initialized. Number of GS: 60408\n",
      "_viewer_render_fn ----> <bound method Runner._viewer_render_fn of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "app_optimizers ----> []\n",
      "cfg ----> Config(disable_viewer=True, ckpt=None, resume=False, run=0, data_dir='/cs/student/projects4/ml/2023/asrivast/datasets/handbag_19/segmented_upright', data_factor=1, result_dir='/cs/student/projects4/ml/2023/asrivast/datasets/handbag_19/segmented_upright/results', test_every=8, patch_size=None, global_scale=1.0, port=8080, batch_size=1, steps_scaler=1.0, max_steps=30000, eval_steps=[7000, 30000], save_steps=[7000, 30000], init_type='sfm', init_num_pts=100000, init_extent=3.0, sh_degree=3, sh_degree_interval=1000, init_opa=0.1, init_scale=1.0, ssim_lambda=0.2, near_plane=0.01, far_plane=10000000000.0, prune_opa=0.005, grow_grad2d=0.0002, grow_scale3d=0.01, prune_scale3d=0.1, refine_start_iter=500, refine_stop_iter=15000, reset_every=3000, refine_every=100, packed=False, sparse_grad=False, absgrad=False, antialiased=False, random_bkgd=False, pose_opt=False, pose_opt_lr=1e-05, pose_opt_reg=1e-06, pose_noise=0.0, app_opt=False, app_embed_dim=16, app_opt_lr=0.001, app_opt_reg=1e-06, depth_loss=False, depth_lambda=0.01, tb_every=100, tb_save_image=False)\n",
      "ckpt_dir ----> /cs/student/projects4/ml/2023/asrivast/datasets/handbag_19/segmented_upright/results/run0/ckpts\n",
      "config_dir ----> /cs/student/projects4/ml/2023/asrivast/datasets/handbag_19/segmented_upright/results/run0/config_files\n",
      "construct_list_of_attributes ----> <bound method Runner.construct_list_of_attributes of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "device ----> cuda\n",
      "eval ----> <bound method Runner.eval of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "lpips ----> LearnedPerceptualImagePatchSimilarity(\n",
      "  (net): _NoTrainLpips(\n",
      "    (scaling_layer): ScalingLayer()\n",
      "    (net): Alexnet(\n",
      "      (slice1): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (slice2): Sequential(\n",
      "        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (slice3): Sequential(\n",
      "        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "      (slice4): Sequential(\n",
      "        (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): ReLU(inplace=True)\n",
      "      )\n",
      "      (slice5): Sequential(\n",
      "        (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (lin0): NetLinLayer(\n",
      "      (model): Sequential(\n",
      "        (0): Dropout(p=0.5, inplace=False)\n",
      "        (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (lin1): NetLinLayer(\n",
      "      (model): Sequential(\n",
      "        (0): Dropout(p=0.5, inplace=False)\n",
      "        (1): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (lin2): NetLinLayer(\n",
      "      (model): Sequential(\n",
      "        (0): Dropout(p=0.5, inplace=False)\n",
      "        (1): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (lin3): NetLinLayer(\n",
      "      (model): Sequential(\n",
      "        (0): Dropout(p=0.5, inplace=False)\n",
      "        (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (lin4): NetLinLayer(\n",
      "      (model): Sequential(\n",
      "        (0): Dropout(p=0.5, inplace=False)\n",
      "        (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (lins): ModuleList(\n",
      "      (0): NetLinLayer(\n",
      "        (model): Sequential(\n",
      "          (0): Dropout(p=0.5, inplace=False)\n",
      "          (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): NetLinLayer(\n",
      "        (model): Sequential(\n",
      "          (0): Dropout(p=0.5, inplace=False)\n",
      "          (1): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (2): NetLinLayer(\n",
      "        (model): Sequential(\n",
      "          (0): Dropout(p=0.5, inplace=False)\n",
      "          (1): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (3-4): 2 x NetLinLayer(\n",
      "        (model): Sequential(\n",
      "          (0): Dropout(p=0.5, inplace=False)\n",
      "          (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "optimizers ----> [Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-15\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00023524067152273494\n",
      "    maximize: False\n",
      "    name: means3d\n",
      "    weight_decay: 0\n",
      "), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-15\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    name: scales\n",
      "    weight_decay: 0\n",
      "), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-15\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    name: quats\n",
      "    weight_decay: 0\n",
      "), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-15\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.05\n",
      "    maximize: False\n",
      "    name: opacities\n",
      "    weight_decay: 0\n",
      "), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-15\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0025\n",
      "    maximize: False\n",
      "    name: sh0\n",
      "    weight_decay: 0\n",
      "), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-15\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.000125\n",
      "    maximize: False\n",
      "    name: shN\n",
      "    weight_decay: 0\n",
      ")]\n",
      "parser ----> <datasets.colmap.Parser object at 0x7f4b9c92efa0>\n",
      "ply_dir ----> /cs/student/projects4/ml/2023/asrivast/datasets/handbag_19/segmented_upright/results/run0/ply_files\n",
      "pose_optimizers ----> []\n",
      "psnr ----> PeakSignalNoiseRatio()\n",
      "rasterize_splats ----> <bound method Runner.rasterize_splats of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "refine_duplicate ----> <bound method Runner.refine_duplicate of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "refine_keep ----> <bound method Runner.refine_keep of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "refine_split ----> <bound method Runner.refine_split of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "render_dir ----> /cs/student/projects4/ml/2023/asrivast/datasets/handbag_19/segmented_upright/results/run0/renders\n",
      "render_traj ----> <bound method Runner.render_traj of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "reset_opa ----> <bound method Runner.reset_opa of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "running_stats ----> {'grad2d': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'count': tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0', dtype=torch.int32)}\n",
      "save_config ----> <bound method Runner.save_config of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "save_ply ----> <bound method Runner.save_ply of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "scene_scale ----> 1.4702541970170933\n",
      "splats ----> ParameterDict(\n",
      "    (means3d): Parameter containing: [torch.cuda.FloatTensor of size 60408x3 (cuda:0)]\n",
      "    (opacities): Parameter containing: [torch.cuda.FloatTensor of size 60408 (cuda:0)]\n",
      "    (quats): Parameter containing: [torch.cuda.FloatTensor of size 60408x4 (cuda:0)]\n",
      "    (scales): Parameter containing: [torch.cuda.FloatTensor of size 60408x3 (cuda:0)]\n",
      "    (sh0): Parameter containing: [torch.cuda.FloatTensor of size 60408x1x3 (cuda:0)]\n",
      "    (shN): Parameter containing: [torch.cuda.FloatTensor of size 60408x15x3 (cuda:0)]\n",
      ")\n",
      "ssim ----> StructuralSimilarityIndexMeasure()\n",
      "stats_dir ----> /cs/student/projects4/ml/2023/asrivast/datasets/handbag_19/segmented_upright/results/run0/stats\n",
      "train ----> <bound method Runner.train of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "trainset ----> <datasets.colmap.Dataset object at 0x7f4b9c8eafd0>\n",
      "update_running_stats ----> <bound method Runner.update_running_stats of <simple_trainer.Runner object at 0x7f4cd04bad00>>\n",
      "valset ----> <datasets.colmap.Dataset object at 0x7f4b9c8eaf70>\n",
      "writer ----> <torch.utils.tensorboard.writer.SummaryWriter object at 0x7f4be9c3b7c0>\n"
     ]
    }
   ],
   "source": [
    "# read config stored in a json file\n",
    "cfg= read_json_and_make_config(\"config.json\")\n",
    "runner = Runner(cfg)\n",
    "\n",
    "#iterate through all attricutes of runner\n",
    "for attr in dir(runner):\n",
    "    if not attr.startswith(\"__\"):\n",
    "        print(attr, \"---->\", getattr(runner, attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.container.ParameterDict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(runner.splats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n",
      "<class 'torch.nn.modules.container.ParameterDict'>\n",
      "means3d torch.Size([95662, 3])\n",
      "opacities torch.Size([95662])\n",
      "quats torch.Size([95662, 4])\n",
      "scales torch.Size([95662, 3])\n",
      "sh0 torch.Size([95662, 1, 3])\n",
      "shN torch.Size([95662, 15, 3])\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load('/cs/student/projects4/ml/2023/asrivast/datasets/handbag_19/segmented_upright/results/ckpts/ckpt_6999.pt')\n",
    "# ckpt is a dictiorary with jsut one key 'splats' whose value is an OrderedDict\n",
    "print(type(ckpt[\"splats\"]))\n",
    "\n",
    "params= ckpt[\"splats\"]\n",
    "splats= torch.nn.ParameterDict(params).to(\"cuda\")\n",
    "print(type(splats))\n",
    "\n",
    "for key, value in splats.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m sparse_grad: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m device: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m optimizers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m         (torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSparseAdam \u001b[38;5;28;01mif\u001b[39;00m sparse_grad \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam)(\n\u001b[1;32m      7\u001b[0m             [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: splats[name]\u001b[38;5;241m.\u001b[39mto(device), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(batch_size), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name}],\n\u001b[1;32m      8\u001b[0m             eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-15\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(batch_size),\n\u001b[1;32m      9\u001b[0m             betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.9\u001b[39m), \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.999\u001b[39m)),\n\u001b[1;32m     10\u001b[0m         )\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name, _, lr \u001b[38;5;129;01min\u001b[39;00m params\n\u001b[1;32m     12\u001b[0m     ]\n",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m sparse_grad: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m device: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m optimizers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m         (torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSparseAdam \u001b[38;5;28;01mif\u001b[39;00m sparse_grad \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam)(\n\u001b[1;32m      7\u001b[0m             [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: splats[name]\u001b[38;5;241m.\u001b[39mto(device), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(batch_size), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name}],\n\u001b[1;32m      8\u001b[0m             eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-15\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(batch_size),\n\u001b[1;32m      9\u001b[0m             betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.9\u001b[39m), \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.999\u001b[39m)),\n\u001b[1;32m     10\u001b[0m         )\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name, _, lr \u001b[38;5;129;01min\u001b[39;00m params\n\u001b[1;32m     12\u001b[0m     ]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size: int = 1,\n",
    "sparse_grad: bool = False,\n",
    "device: str = \"cuda\"\n",
    "\n",
    "# optimizers = [\n",
    "#         (torch.optim.SparseAdam if sparse_grad else torch.optim.Adam)(\n",
    "#             [{\"params\": splats[name].to(device), \"lr\": lr * math.sqrt(batch_size), \"name\": name}],\n",
    "#             eps=1e-15 / math.sqrt(batch_size),\n",
    "#             betas=(1 - batch_size * (1 - 0.9), 1 - batch_size * (1 - 0.999)),\n",
    "#         )\n",
    "#         for name, _, lr in params\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/student/projects3/COMP0197/grp1/mini/envs/gaussian_splatting/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: 21.958, SSIM: 0.8073, LPIPS: 0.271 Time: 0.449s/image Number of GS: 95662\n"
     ]
    }
   ],
   "source": [
    "runner.eval(80085)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom progress and step with tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  93%|█████████▎| 70/75 [00:03<00:00, 18.48it/s, loss=0.473, acc=0.785]\n"
     ]
    }
   ],
   "source": [
    "# custom stating point and update in steps on tqdm bars\n",
    "from tqdm import tqdm\n",
    "import time, random\n",
    "\n",
    "first_iter= 0\n",
    "steps= 10\n",
    "last_iter= steps*10\n",
    "\n",
    "progress_bar = tqdm(range(first_iter, last_iter), desc='Training progress', )\n",
    "\n",
    "for i in range(first_iter, last_iter):\n",
    "    time.sleep(0.05)\n",
    "    if i % 10 == 0:\n",
    "        progress_bar.set_postfix({'loss': random.random(), 'acc': random.random()})\n",
    "        progress_bar.update(steps)\n",
    "progress_bar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian_splatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
